<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Edwardyam.GitHub.io : Welcome">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <script type="text/javascript" src="MathJax-2.6-latest/MathJax.js?config=default"></script>
    <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>

    <title>Edwardyam.GitHub.io</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="content.html">View All Articles</a>

          <h1 id="project_title">京东爬虫</h1>
          <h2 id="project_tagline">JD Crawler</h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Crawler of JD</h3>

<p>
My tutor leave me a homework, progamming a crawler of JD which can get products' names, price and comments automatically. Under the advice from Internet, I chose python to progame it.<br/><br/>

In my opinion, one of the most important things for a crawler programmer is observation. We have to get the html of each websites, find the common points and get message with the help of them. There are two parts in my crawler. The first part is getting message. In this part, it can get the produt's name, price and top 10 comments based on the url of the products. The second part is getting url. It can get all products' url which are in this web based on the url of search result web.<br/><br/>

The first question is how to get products' names. There are two types of code which is used to present products' names. The first one is using the tag h1. The other is using a div and a class named "sku-name". With the help of this two features, we can get products' name easily.<br/><br/>

The next question is how to get the price of the product. It is interesting that the HTML code getting by the crawler does not contain the price. As a result, we have to send a request to get the price. When we open a web of product, we can press F12 to see the details of this web. At this time,if we turn to the network tag and refresh the web, we can see lots of request in here. What we need to do is to find the request which is used to get the price. After we send the request, we will get the price in JSON.<br/><br/>

At last, we have to get the comments. every produts may hava thousands of comments. As a result, we only get the top ten comments in here. There are also no comments in the HTML which is get by the crawler, so we also have to find the request and get the comments. After we send the request, we can get the comments in JSONP, and we can translate it into JSON and get the comments one by one.<br/><br/>

After we can ge all the information we need. All we only to do is to provide the url automatically. In this programme, we start at a product's list web, and find all the 60 products url and then get their information which will be stored in database later.<br/><br/>

All the code introduced above is in <a href="https://github.com/EdwardYam/python/blob/master/crawler/JDcrawler/JDcrawler.py">here</a>. Welcome to contact me if you have any advice or question.<br/><br/>email:edwardyam@outlook.com
</p>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p>written by <a href="https://edwardyam.github.io/">Edward Yam</a></p>
      </footer>
    </div>



  </body>
</html>
